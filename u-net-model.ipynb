{"cells":[{"metadata":{"id":"ypzomLQzYJYf","outputId":"8b8a3745-d4e5-48e1-b8f3-9964226930a6","trusted":true},"cell_type":"code","source":"import torch\n\n# If there's a GPU available...\nif torch.cuda.is_available():    \n\n    # Tell PyTorch to use the GPU.    \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"id":"nc2715M3W92O","outputId":"f8b2c484-f5f6-4ae8-abb8-27a50c0adb09","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport time\nimport tqdm\nimport random\nimport collections\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom PIL import Image\nfrom functools import partial\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm as tq\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n\n# ablumentations for easy image augmentation for input as well as output\nimport albumentations as albu\n# from albumentations import torch as AT\nplt.style.use('bmh')","execution_count":null,"outputs":[]},{"metadata":{"id":"z2d0WrNqNbVX","trusted":true},"cell_type":"code","source":"\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"id":"oNHEIe4sN2Tf","trusted":true},"cell_type":"code","source":"use_gpu = torch.cuda.is_available()\nSEED = 42","execution_count":null,"outputs":[]},{"metadata":{"id":"iDiNOMB5kWp8","trusted":true},"cell_type":"code","source":"X= ['{}'.format(num) for num in range(1, 2881)]\ny= ['{}'.format(num) for num in range(1, 2881)]","execution_count":null,"outputs":[]},{"metadata":{"id":"ysZqr4nbkyJK","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"id":"LA8smvFpl2Mc","trusted":true},"cell_type":"code","source":"train=pd.DataFrame()\ntest=pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"id":"MCiCDc2zl2Zq","trusted":true},"cell_type":"code","source":"train['x_train']=X_train\ntrain['y_train']=y_train\ntest['x_test']=X_test\ntest['y_test']=y_test","execution_count":null,"outputs":[]},{"metadata":{"id":"9ADsR2CGQToz","trusted":true},"cell_type":"code","source":"from skimage.io import imread, imsave\nimport skimage.io as io","execution_count":null,"outputs":[]},{"metadata":{"id":"6qjFGN3Jf0HQ","trusted":true},"cell_type":"code","source":"class Super_resol_Dataset():\n    \n    def __init__(self, dataset, root_dir_x, root_dir_y, transform1=None, transform2=None):\n\n        self.data = dataset\n        self.root_dir_x = root_dir_x\n        self.root_dir_y = root_dir_y\n        self.transform1 = transform1\n        self.transform2 = transform2\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx\n        # idx = idx\n        img_name = self.root_dir_x + self.data.iloc[idx, 0]\n        image = Image.open(img_name+\".png\")\n\n        label_name =  self.root_dir_y +self.data.iloc[idx, 1]\n        label = Image.open(label_name+\".png\")        \n        if self.transform1 is not None:\n            image = self.transform1(image)\n        if self.transform2 is not None:\n            label = self.transform2(label)\n\n        return image, label\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path1='../input/sem-data/sem_128/image/'\npath2='../input/sem-data/sem_128/label/'","execution_count":null,"outputs":[]},{"metadata":{"id":"4D97us8LiEAB","trusted":true},"cell_type":"code","source":"batch_size=32\ntrain_transform = transforms.Compose([transforms.Resize((128,128)),transforms.ToTensor()])\ntest_transform = transforms.Compose([transforms.Resize((128,128)),transforms.ToTensor()])\n\ntrainset = Super_resol_Dataset(dataset=train,root_dir_x=path1,\n                               root_dir_y=path2,transform1=train_transform,transform2=test_transform)\ntestset = Super_resol_Dataset(dataset=test,root_dir_x=path1,\n                               root_dir_y=path2,transform1=train_transform,transform2=test_transform)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ihj5LkKfiLFY","trusted":true},"cell_type":"code","source":"trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size, shuffle=True, num_workers=1)\ntestloader = torch.utils.data.DataLoader(testset,batch_size=batch_size, shuffle=False, num_workers=1 )","execution_count":null,"outputs":[]},{"metadata":{"id":"1xguAAnuajpN","outputId":"f777414c-3b92-443d-db73-dd8f5a163d55","trusted":true},"cell_type":"code","source":"len(trainset)","execution_count":null,"outputs":[]},{"metadata":{"id":"N9zQS6mYiWb8","outputId":"8170fa6f-23aa-434d-e4bd-f011fcab737f","trusted":true},"cell_type":"code","source":"\ntrainiter = iter(trainloader)\nfeatures, labels = next(trainiter)\nfeatures.shape, labels.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"DQvJSe5oiWwu","trusted":true},"cell_type":"code","source":"use_gpu = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","execution_count":null,"outputs":[]},{"metadata":{"id":"tLJ7sc__-PTr","trusted":true},"cell_type":"code","source":"class DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\n\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n\n        # if bilinear, use the normal convolutions to reduce the number of channels\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        # input is CHW\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n                        diffY // 2, diffY - diffY // 2])\n        # if you have padding issues, see\n        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        return self.conv(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"vfhv0ffpIdip","trusted":true},"cell_type":"code","source":"\nclass UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n\n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512, 1024 // factor)\n        self.up1 = Up(1024, 512 // factor, bilinear)\n        self.up2 = Up(512, 256 // factor, bilinear)\n        self.up3 = Up(256, 128 // factor, bilinear)\n        self.up4 = Up(128, 64, bilinear)\n        self.outc = OutConv(64, n_classes)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits","execution_count":null,"outputs":[]},{"metadata":{"id":"LW1SWK13iaRQ","trusted":true},"cell_type":"code","source":"save_file_name = 'segmentation_128.pt'","execution_count":null,"outputs":[]},{"metadata":{"id":"gaanskuZygFD","trusted":true},"cell_type":"code","source":"import torch\nfrom torch.autograd import Function\nclass DiceCoeff(Function):\n    \"\"\"Dice coeff for individual examples\"\"\"\n\n    def forward(self, input, target):\n        self.save_for_backward(input, target)\n        eps = 0.0001\n        self.inter = torch.dot(input.view(-1), target.view(-1))\n        self.union = torch.sum(input) + torch.sum(target) + eps\n\n        t = (2 * self.inter.float() + eps) / self.union.float()\n        return t\n\n    # This function has only a single output, so it gets only one gradient\n    def backward(self, grad_output):\n\n        input, target = self.saved_variables\n        grad_input = grad_target = None\n\n        if self.needs_input_grad[0]:\n            grad_input = grad_output * 2 * (target * self.union - self.inter) \\\n                         / (self.union * self.union)\n        if self.needs_input_grad[1]:\n            grad_target = None\n\n        return grad_input, grad_target\n\n\ndef dice_coeff(input, target):\n    \"\"\"Dice coeff for batches\"\"\"\n    if input.is_cuda:\n        s = torch.FloatTensor(1).cuda().zero_()\n    else:\n        s = torch.FloatTensor(1).zero_()\n\n    for i, c in enumerate(zip(input, target)):\n        s = s + DiceCoeff().forward(c[0], c[1])\n\n    return s / (i + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytorch-msssim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM","execution_count":null,"outputs":[]},{"metadata":{"id":"kLX6eivOCjms","trusted":true},"cell_type":"code","source":"\ndef training(model,criterion, optimizer,scheduler,n_epochs):\n  # n_epochs = 32\n\n    valid_loss_min = np.Inf # track change in validation loss\n    for epoch in range(1, n_epochs+1):\n        train_loss = 0.0\n        valid_loss = 0.0\n        dice_train = 0.0\n        dice_test = 0.0\n        ssim_val= 0.0\n        ms_ssim_val =0.0\n      ###################\n      # train the model #\n      ###################\n        model.train()\n      # bar = tq(trainloader, postfix={\"train_loss\":0.0})\n        for i,inputs in enumerate(trainloader):\n            data,target = inputs\n          # print(data.size(0))\n            if use_gpu:data, target = data.cuda(), target.cuda()\n          # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n          # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n          # calculate the batch loss\n            loss = criterion(output, target)\n          #print(loss)\n          # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n          # perform a single optimization step (parameter update)\n            optimizer.step()\n          # update training loss\n            train_loss += loss.item()*data.size(0)\n            output= torch.sigmoid(output)\n            output = (output > 0.5).float()\n            dice_cof = dice_coeff(output, target).item()\n            dice_train +=  dice_cof * data.size(0)\n          # bar.set_postfix(ordered_dict={\"train_loss\":loss.item()})\n        \n        model.eval()\n      # del data, target\n        with torch.no_grad():\n            for i,inputs in enumerate(testloader):\n                data,target = inputs\n                if use_gpu:\n                      data, target = data.cuda(), target.cuda()\n              # forward pass: compute predicted outputs by passing inputs to the model\n                output = model(data)\n            # calculate the batch loss\n                loss = criterion(output, target)\n            # update average validation loss \n                valid_loss += loss.item()*data.size(0)\n                output= torch.sigmoid(output)\n                output = (output > 0.5).float()\n                dice_cof = dice_coeff(output, target).item()\n                dice_test +=  dice_cof * data.size(0)\n                ssim_val =ssim_val+ ssim( output, target, data_range=1, size_average=True)* data.size(0)\n#                 ms_ssim_val =ms_ssim_val+ ms_ssim( output, target, data_range=1, size_average=True )* data.size(0) \n            # bar.set_postfix(ordered_dict={\"valid_loss\":loss.item(), \"dice_score\":dice_cof})\n    \n        train_loss = train_loss/len(trainloader.dataset)\n        valid_loss = valid_loss/len(testloader.dataset)\n        dice_test = dice_test/len(testloader.dataset)\n        dice_train = dice_train/len(trainloader.dataset)\n        ssim_val = ssim_val/len(testloader.dataset)\n#         ms_ssim_val = ms_ssim_val/len(testloader.dataset)\n\n        train_loss_list.append(train_loss)\n        valid_loss_list.append(valid_loss)\n        dice_train_list.append(dice_train)\n        dice_test_list.append(dice_test)\n        lr_rate_list.append([param_group['lr'] for param_group in optimizer.param_groups])\n\n      # print training/validation statistics \n        print('Epoch: {}  Training Loss: {:.6f}  Validation Loss: {:.6f} Dice test: {:.6f}   ssim Score: {:.6f}  dice train: {:.6f}'.format(\n            epoch, train_loss, valid_loss, dice_test,ssim_val,dice_train))\n      \n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            torch.save(model.state_dict(), save_file_name)\n            valid_loss_min = valid_loss\n      \n        scheduler.step(valid_loss)","execution_count":null,"outputs":[]},{"metadata":{"id":"8cwDQLvdDQpX","outputId":"3c847280-cc07-4d7e-de77-1b577ebbd2f2","trusted":true},"cell_type":"code","source":"from torchvision.transforms import *\n# del model\nmodel = UNet(n_channels=1, n_classes=1, bilinear=True)\n\nif use_gpu:\n    print('GPU is avaialble!')\n    model = model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"id":"07JLX826Vr7E","trusted":true},"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.99)\ncurrent_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',factor=0.2, patience=2)","execution_count":null,"outputs":[]},{"metadata":{"id":"cFGUAn85WXgS","trusted":true},"cell_type":"code","source":"train_loss_list = []\nvalid_loss_list = []\ndice_train_list = []\ndice_test_list = []\nlr_rate_list = []","execution_count":null,"outputs":[]},{"metadata":{"id":"bQ4cJSZ9XOj-","outputId":"d7b6561a-7fa4-45e1-e184-ae06e07b188b","trusted":true},"cell_type":"code","source":"training(model, criterion,optimizer,scheduler,n_epochs=40)","execution_count":null,"outputs":[]},{"metadata":{"id":"HJXFKCzHXPeU","outputId":"b39d5541-e15c-4617-fe91-723238d731f7","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot([i[0] for i in lr_rate_list])\nplt.ylabel('learing rate during training', fontsize=22)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Qp87gT8AXQL7","outputId":"50fd084f-682b-4e27-c555-e3ca0407fde3","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(train_loss_list,  marker='o', label=\"Training Loss\")\nplt.plot(valid_loss_list,  marker='o', label=\"Validation Loss\")\nplt.ylabel('loss', fontsize=22)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(dice_train_list,  marker='o', label=\"Training Dice Score\")\nplt.plot(dice_test_list,  marker='o', label=\"Validation Dice Score\")\nplt.ylabel('Dice Coefficient', fontsize=22)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Z7Fadn6vXPFn","trusted":true},"cell_type":"code","source":"# load best model\nmodel.load_state_dict(torch.load('./segmentation_128.pt'))\nmodel.cuda()\nmodel.eval();","execution_count":null,"outputs":[]},{"metadata":{"id":"GMIo8YYopy4T","trusted":true},"cell_type":"code","source":"def dice(img1, img2):\n    img1 = np.asarray(img1).astype(np.bool)\n    img2 = np.asarray(img2).astype(np.bool)\n\n    intersection = np.logical_and(img1, img2)\n\n    return 2.0 * intersection.sum() / (img1.sum() + img2.sum())","execution_count":null,"outputs":[]},{"metadata":{"id":"TP_7xgaimwHi","trusted":true},"cell_type":"code","source":"test_transform = transforms.Compose([transforms.Resize((1024,1024)),transforms.ToTensor()])\n\nfrom PIL import Image, ImageOps  \nfrom torch.autograd import Variable\n\ndef image_loader(image_name):\n    image = Image.open(image_name)\n    image = test_transform(image).float()\n    image = Variable(image, requires_grad=True)\n    image = image.unsqueeze(0) \n    return image.cuda()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"qrOWkItU_Vwj","trusted":true},"cell_type":"code","source":"#Testing image\ninputs = image_loader('../input/sem-data/sem/sem/image/4.png')\noutput = model(inputs)\nprobs = torch.sigmoid(output)\nprobs = probs.squeeze(0)\ntf = transforms.Compose(\n            [\n                transforms.ToPILImage(),\n                transforms.Resize((1024,1024)),\n                transforms.ToTensor()\n            ]\n        )\n\nprobs = tf(probs.cpu())\nfull_mask = probs.squeeze().cpu().numpy()\nmask = full_mask>0.5\nresult=Image.fromarray((mask * 255).astype(np.uint8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"truth = Image.open('../input/sem-data/sem/sem/label/4.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.save('result.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dice(result,truth))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}